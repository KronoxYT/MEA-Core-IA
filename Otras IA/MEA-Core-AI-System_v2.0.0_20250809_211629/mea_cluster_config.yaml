# MEA-Core Distributed AI Cluster Configuration
# Lightweight distributed inference farm for local AI processing

cluster:
  discovery: mdns
  controller_host: localhost
  controller_port: 8765
  transport: tcp  # tcp, grpc (when available)
  compression: fp16
  broadcast_port: 8766

scheduling:
  policy: shortest_job_first  # shortest_job_first, priority, load_balanced
  gpu_affinity: true
  max_batch_latency_ms: 60
  heartbeat_timeout_seconds: 30
  task_retry_attempts: 2
  load_balancing: true

models:
  intent_classifier:
    type: mlp
    backend: numpy
    input_dim: 128
    hidden_dims: [64, 32]
    output_dim: 4
    quantization: none
    gpu_allowed: false
    memory_requirement_mb: 32
    
  document_classifier:
    type: mlp
    backend: numpy
    input_dim: 256
    hidden_dims: [128, 64]
    output_dim: 5
    quantization: int8
    gpu_allowed: false
    memory_requirement_mb: 64
    
  sentiment_classifier:
    type: linear
    backend: ftrl
    n_features: 100
    quantization: none
    gpu_allowed: false
    memory_requirement_mb: 8
    
  text_embedder:
    type: mini_transformer
    backend: numpy
    vocab_size: 5000
    d_model: 128
    n_heads: 4
    n_layers: 2
    quantization: int8
    gpu_allowed: true
    memory_requirement_mb: 256

# Task types and their resource requirements
tasks:
  ocr:
    cpu_cores: 1
    memory_mb: 256
    gpu_required: false
    parallel_batch_size: 4
    estimated_time_per_page: 0.5
    
  bm25_index:
    cpu_cores: 2
    memory_mb: 512
    gpu_required: false
    parallel_batch_size: 8
    estimated_time_per_doc: 0.1
    
  embeddings:
    cpu_cores: 1
    memory_mb: 512
    gpu_required: true
    gpu_memory_mb: 256
    parallel_batch_size: 16
    estimated_time_per_chunk: 0.05
    
  classify:
    cpu_cores: 1
    memory_mb: 128
    gpu_required: false
    parallel_batch_size: 32
    estimated_time_per_item: 0.01
    
  summarize:
    cpu_cores: 2
    memory_mb: 256
    gpu_required: false
    parallel_batch_size: 4
    estimated_time_per_doc: 2.0
    
  stt:
    cpu_cores: 1
    memory_mb: 512
    gpu_required: true
    gpu_memory_mb: 512
    parallel_batch_size: 2
    estimated_time_per_second: 0.2
    
  tts:
    cpu_cores: 1
    memory_mb: 512
    gpu_required: true
    gpu_memory_mb: 256
    parallel_batch_size: 4
    estimated_time_per_sentence: 0.5

# Worker node configurations
worker_profiles:
  lightweight:
    description: "Basic CPU worker for low-resource devices"
    min_cpu_cores: 2
    min_memory_mb: 2048
    gpu_required: false
    supported_tasks: [ocr, bm25_index, classify, summarize]
    max_concurrent_tasks: 2
    
  standard:
    description: "Standard worker with moderate resources"
    min_cpu_cores: 4
    min_memory_mb: 4096
    gpu_required: false
    supported_tasks: [ocr, bm25_index, classify, summarize]
    max_concurrent_tasks: 4
    
  gpu_enhanced:
    description: "GPU-enabled worker for intensive AI tasks"
    min_cpu_cores: 4
    min_memory_mb: 8192
    gpu_required: true
    min_gpu_memory_mb: 2048
    supported_tasks: [ocr, bm25_index, embeddings, classify, summarize, stt, tts]
    max_concurrent_tasks: 8
    
  mobile_web:
    description: "Mobile browser worker using WebGPU/WebAssembly"
    min_cpu_cores: 2
    min_memory_mb: 1024
    gpu_required: false
    webgpu_enabled: true
    supported_tasks: [classify, summarize]
    max_concurrent_tasks: 1
    connection_type: websocket

# System resource management
resources:
  # CPU utilization limits
  max_cpu_usage_percent: 80
  cpu_core_reserve: 1
  
  # Memory management
  max_memory_usage_percent: 75
  memory_reserve_mb: 512
  
  # GPU management (when available)
  max_gpu_memory_usage_percent: 90
  gpu_memory_reserve_mb: 256
  
  # Network bandwidth management
  max_network_bandwidth_mbps: 100
  compression_enabled: true
  batch_size_auto_adjust: true

# Caching and optimization
caching:
  model_weights_cache: true
  cache_size_mb: 1024
  cache_location: "./data/cache/"
  preload_models: ["intent_classifier", "document_classifier"]
  
  # Content-addressable storage for deduplication
  content_addressed_storage: true
  embedding_cache: true
  result_cache_ttl_seconds: 3600

# Security and monitoring
security:
  tls_enabled: false  # Enable for production
  allowed_hosts: ["127.0.0.1", "localhost", "192.168.1.*"]
  authentication_required: false
  worker_whitelist: []
  
monitoring:
  enable_telemetry: true
  metrics_port: 9090
  log_level: INFO
  performance_profiling: false
  
  # Dashboard configuration
  dashboard:
    enabled: true
    port: 8080
    auto_refresh_seconds: 5
    show_worker_details: true
    show_task_queue: true
    show_performance_metrics: true

# Failover and resilience
failover:
  enable_auto_recovery: true
  worker_failure_threshold: 3
  task_timeout_seconds: 300
  graceful_shutdown_timeout: 30
  
  # Degradation strategies
  degradation:
    no_gpu_fallback: cpu_only
    low_memory_mode: reduce_batch_size
    high_load_mode: queue_throttling
    network_issues: local_processing_only

# Development and testing
development:
  mock_workers: 0  # Number of simulated workers for testing
  debug_mode: false
  profiling_enabled: false
  test_task_interval_seconds: 0  # 0 = disabled
  
# Integration settings
integration:
  # MEA-Core specific settings
  mea_core_integration: true
  bm25_distributed: true
  neural_network_distributed: true
  voice_processing_distributed: false  # Keep local for latency
  
  # External service integration
  api_gateway_enabled: false
  webhook_notifications: false
  external_model_registry: false

# Version and compatibility
version: "1.0.0"
compatibility:
  min_python_version: "3.8"
  required_packages: ["numpy", "psutil"]
  optional_packages: ["GPUtil", "requests", "websockets"]
  
# Example deployment scenarios
deployment_scenarios:
  single_machine:
    description: "Single machine with multiple worker processes"
    workers: 1
    resource_sharing: true
    
  home_network:
    description: "Multiple devices in home network"
    discovery_method: mdns
    auto_scaling: true
    
  office_cluster:
    description: "Office environment with mixed devices"
    load_balancing: sophisticated
    priority_queues: true
    
  hybrid_mobile:
    description: "Including mobile devices as workers"
    mobile_workers: true
    web_workers: true
    battery_awareness: true